Lexical
Ohne reshape vor der konkatenation

    ### Tunable Variables
    numEpoch = 15            # Number of Epochs for training
    trainableEmbeddings = False
    activationFunction = "TanH"     #"CNN = tanh + FCL = Relu"
    lossFunction = "Hinge-Loss"
    learningRate = 0.05
    dropout = 0.50
    optimizerFunction = "Stochastic Gradient Descent"

    ### Static Variables
    batchSize = 100          # Batchsize for training
    evalFrequency = 1       # Evaluation frequency (epoch % evalFrequency == 0)
    numCPUs = 10            # Number of CPU's to be used
    filterNumber2WC = 20    # Number of filters for 2-Word-Context
    filterNumber3WC = 20    # Number of filters for 3-Word-Context
    filterNumber4WC = 20    # Number of filters for 4-Word-Context
    typeOfCNN = "CNN + 1 Fully-Connected-Layer"

    pathTraining = "NN_Input_Files/trainData_Embeddings.pickle"
    pathEvaluation = "NN_Input_Files/devData_Embeddings.pickle"
    pathEmbeddings = "dict/embeddingMatrix_np_acolex_full.pickle"

    1. Lauf: 0.722414    Log: 18-02-20-11-53-40
    2. Lauf: 0.724881    Log: 18-02-20-13-30-04

    ### Tunable Variables
    numEpoch = 15            # Number of Epochs for training
    trainableEmbeddings = True
    activationFunction = "TanH"     #"CNN = tanh + FCL = Relu"
    lossFunction = "Hinge-Loss"
    learningRate = 0.05
    dropout = 0.50
    optimizerFunction = "Stochastic Gradient Descent"

    ### Static Variables
    batchSize = 100          # Batchsize for training
    evalFrequency = 1       # Evaluation frequency (epoch % evalFrequency == 0)
    numCPUs = 10            # Number of CPU's to be used
    filterNumber2WC = 20    # Number of filters for 2-Word-Context
    filterNumber3WC = 20    # Number of filters for 3-Word-Context
    filterNumber4WC = 20    # Number of filters for 4-Word-Context
    typeOfCNN = "CNN + 1 Fully-Connected-Layer"

    pathTraining = "NN_Input_Files/trainData_Embeddings.pickle"
    pathEvaluation = "NN_Input_Files/devData_Embeddings.pickle"
    pathEmbeddings = "dict/embeddingMatrix_np_acolex_full.pickle"

    1. Lauf: 0.778655 Log: 18-02-20-14-43-43


Acolex
Ohne reshape vor der konkatenation

    ### Tunable Variables
    numEpoch = 15                    # Number of Epochs for training
    trainableEmbeddings = False
    activationFunction = "Sigmoid"     #"CNN = tanh + FCL = Relu"
    lossFunction = "Hinge-Loss"
    learningRate = 0.01
    dropout = 0.50
    optimizerFunction = "Stochastic Gradient Descent"
    filterNumberMFCC = 20    # Number of filters for the MFCC features
    mfccFilterSize = 100

    ### Static Variables
    batchSize = 100         # Batchsize for training
    evalFrequency = 1       # Evaluation frequency (epoch % evalFrequency == 0)
    numCPUs = 10            # Number of CPU's to be used
    filterNumber2WC = 20    # Number of filters for 2-Word-Context
    filterNumber3WC = 20    # Number of filters for 3-Word-Context
    filterNumber4WC = 20    # Number of filters for 4-Word-Context
    numberMFCCFeatures = 2000
    typeOfCNN = "CNN + 1 Fully-Connected-Layer"

    pathTraining = "NN_Input_Files/trainData_acolex_Embeddings.pickle"
    pathEvaluation = "NN_Input_Files/devData_acolex_Embeddings.pickle"
    pathEmbeddings = "dict/embeddingMatrix_np_acolex_full.pickle"

    1. Lauf: 0.69824 Log: 18-02-20-14-40-44